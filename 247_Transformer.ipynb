{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uykYUjDswO_W"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WsCniUN7y7vm"},"outputs":[],"source":["cd drive/MyDrive/C247-NNDL/"]},{"cell_type":"markdown","metadata":{"id":"0qsndJ9PzbZq"},"source":["# IMPORTS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OaIUyjExzUq2"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","from tqdm import tqdm\n","\n","from matplotlib.collections import LineCollection\n","\n","from sklearn.metrics import accuracy_score\n","\n","%pylab inline\n","\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.models as models\n","import torchvision.transforms as T\n","import torch.nn.functional as F\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","writer = SummaryWriter(log_dir=\"Results/runs\")\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"MHNlNIW3_zEN"},"source":["# DATA PREPROCESSING AND RESHAPING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iUrXl5r3zZ-V"},"outputs":[],"source":["## Loading the numpy arrays corresponding to the EEG dataset\n","\n","X_test = np.load(\"./Dataset/X_test.npy\")\n","y_test = np.load(\"./Dataset/y_test.npy\")\n","person_train_valid = np.load(\"./Dataset/person_train_valid.npy\")\n","X_train_valid = np.load(\"./Dataset/X_train_valid.npy\")\n","y_train_valid = np.load(\"./Dataset/y_train_valid.npy\")\n","person_test = np.load(\"./Dataset/person_test.npy\")\n","\n","## Printing the shapes of the numpy arrays\n","\n","print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n","print ('Test data shape: {}'.format(X_test.shape))\n","print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n","print ('Test target shape: {}'.format(y_test.shape))\n","print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n","print ('Person test shape: {}'.format(person_test.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xsYMtmfzpS1"},"outputs":[],"source":["## Adjusting the labels to {0,1,2,3}\n","\n","# Cue onset left - 0\n","# Cue onset right - 1\n","# Cue onset foot - 2\n","# Cue onset tongue - 3\n","\n","y_train_valid -= 769\n","y_test -= 769"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYgDVuaN3G8Z"},"outputs":[],"source":["print(np.unique(y_train_valid, return_counts=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wP7dyOexzwXj"},"outputs":[],"source":["## Creating the training and validation sets\n","\n","# First generating the training and validation indices using random splitting\n","# ind_valid = np.random.choice(2115, 100, replace=False)\n","# ind_train = np.array(list(set(range(2115)).difference(set(ind_valid))))\n","# \n","# # Creating the training and validation sets using the generated indices\n","# (x_train, x_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n","# (y_train, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n","# print('Shape of training set:',x_train.shape)\n","# print('Shape of validation set:',x_valid.shape)\n","# print('Shape of training labels:',y_train.shape)\n","# print('Shape of validation labels:',y_valid.shape)"]},{"cell_type":"markdown","source":["# DATA PREPROCESSING AND AUGMENTATION"],"metadata":{"id":"hMPEuEtME9wr"}},{"cell_type":"code","source":["## Visualizing the data\n","\n","ch_data = X_train_valid[:,8,:]\n","\n","\n","class_0_ind = np.where(y_train_valid == 0)\n","ch_data_class_0 = ch_data[class_0_ind]\n","avg_ch_data_class_0 = np.mean(ch_data_class_0,axis=0)\n","\n","\n","class_1_ind = np.where(y_train_valid == 1)\n","ch_data_class_1 = ch_data[class_1_ind]\n","avg_ch_data_class_1 = np.mean(ch_data_class_1,axis=0)\n","\n","class_2_ind = np.where(y_train_valid == 2)\n","ch_data_class_2 = ch_data[class_2_ind]\n","avg_ch_data_class_2 = np.mean(ch_data_class_2,axis=0)\n","\n","class_3_ind = np.where(y_train_valid == 3)\n","ch_data_class_3 = ch_data[class_3_ind]\n","avg_ch_data_class_3 = np.mean(ch_data_class_3,axis=0)\n","\n","\n","plt.plot(np.arange(1000),avg_ch_data_class_0)\n","plt.plot(np.arange(1000),avg_ch_data_class_1)\n","plt.plot(np.arange(1000),avg_ch_data_class_2)\n","plt.plot(np.arange(1000),avg_ch_data_class_3)\n","plt.axvline(x=500, label='line at t=500',c='cyan')\n","\n","plt.legend([\"Cue Onset left\", \"Cue Onset right\", \"Cue onset foot\", \"Cue onset tongue\"])"],"metadata":{"id":"21PwKZluE8v4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def data_prep(X,y,sub_sample,average,noise):\n","    \n","    total_X = None\n","    total_y = None\n","    \n","    # Trimming the data (sample,22,1000) -> (sample,22,500)\n","    X = X[:,:,0:500]\n","    print('Shape of X after trimming:',X.shape)\n","    \n","    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n","    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n","    \n","    \n","    total_X = X_max\n","    total_y = y\n","    print('Shape of X after maxpooling:',total_X.shape)\n","    \n","    # Averaging + noise \n","    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n","    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n","    \n","    total_X = np.vstack((total_X, X_average))\n","    total_y = np.hstack((total_y, y))\n","    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n","    \n","    # Subsampling\n","    \n","    for i in range(sub_sample):\n","        \n","        X_subsample = X[:, :, i::sub_sample] + \\\n","                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n","            \n","        total_X = np.vstack((total_X, X_subsample))\n","        total_y = np.hstack((total_y, y))\n","        \n","    \n","    print('Shape of X after subsampling and concatenating:',total_X.shape)\n","    return total_X,total_y"],"metadata":{"id":"1E_BSM8CErRQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Preprocessing the dataset\n","\n","X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True)\n","X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True)\n","\n","print(X_train_valid_prep.shape)\n","print(y_train_valid_prep.shape)\n","print(X_test_prep.shape)\n","print(y_test_prep.shape)"],"metadata":{"id":"aJOjNka_E0uP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Creating the training and validation sets\n","\n","# First generating the training and validation indices using random splitting\n","ind_valid = np.random.choice(8460, 1500, replace=False)\n","ind_train = np.array(list(set(range(8460)).difference(set(ind_valid))))\n","\n","# Creating the training and validation sets using the generated indices\n","(x_train, x_valid) = X_train_valid_prep[ind_train], X_train_valid_prep[ind_valid] \n","(y_train, y_valid) = y_train_valid_prep[ind_train], y_train_valid_prep[ind_valid]\n","print('Shape of training set:',x_train.shape)\n","print('Shape of validation set:',x_valid.shape)\n","print('Shape of training labels:',y_train.shape)\n","print('Shape of validation labels:',y_valid.shape)\n","\n","X_test = X_test_prep\n","y_test = y_test_prep\n","\n","print('Shape of test set:',X_test.shape)\n","print('Shape of test labels:',y_test.shape)"],"metadata":{"id":"KmQmg0epFX2w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z8nvenni_up-"},"source":["# VISUALIZING A SAMPLE EEG DATA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H--iTcRq8Ht0"},"outputs":[],"source":["# Taken from: https://notebook.community/joannekoong/neuroscience_tutorials/basic/1.%20Load%20EEG%20data%20and%20plot%20ERP\n","\n","def plot_eeg(EEG, vspace=100, color='k'):   \n","    bases = vspace * np.arange(22)    \n","    EEG = EEG.T + bases\n","    \n","    # Calculate a timeline in seconds, assuming that the sample rate of the EEG recorder was 2048 Hz.\n","    samplerate = 2048\n","    time = arange(EEG.shape[0]) / samplerate\n","    \n","    # Plot EEG versus time\n","    plot(time, EEG, color=color)\n","    grid()\n","    xlabel('Time (s)')\n","    ylabel('Channels')\n","    gca().yaxis.set_ticks(bases)\n","    title('EEG data for a single sample')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTZQAy6h95su"},"outputs":[],"source":["figure(figsize=(15,22))\n","plot_eeg(X_train_valid[0])"]},{"cell_type":"markdown","metadata":{"id":"Cp4RiVO_1NTf"},"source":["# DATALOADER"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b2n3BiPEHezw"},"outputs":[],"source":["x_train = np.swapaxes(x_train, 1, 2)\n","x_valid = np.swapaxes(x_valid, 1, 2)\n","x_test = np.swapaxes(X_test, 1, 2)\n","\n","print('Shape of training set after dimension reshaping:',x_train.shape)\n","print('Shape of validation set after dimension reshaping:',x_valid.shape)\n","print('Shape of test set after dimension reshaping:',x_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pkxUQnyU4F2i"},"outputs":[],"source":["# Normalize each channel to have mean 0 and std 1\n","def standardize(x):\n","    mean = np.mean(x, axis=1)\n","    var = np.var(x, axis=1)\n","\n","    return (x - mean[:, None]) / np.sqrt(var)[:, None]\n","\n","x_train = standardize(x_train)\n","x_valid = standardize(x_valid)\n","x_test = standardize(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e8abe4DA1M20"},"outputs":[],"source":["class LoadData(Dataset):\n","    def __init__(self, data, labels):\n","        self.data = torch.Tensor(data)\n","        tensor_labels = torch.Tensor(labels).long()\n","        self.labels = F.one_hot(tensor_labels, num_classes=4)\n","\n","    def __len__(self) -> int:\n","        return len(self.data)\n","    \n","    def __getitem__(self, index: int):\n","        input_data = self.data[index]\n","        input_label = self.labels[index]\n","        return (input_data, input_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqBINydo3NQy"},"outputs":[],"source":["train_dataset = LoadData(data=x_train, labels=y_train,)\n","val_dataset = LoadData(data=x_valid, labels=y_valid,)\n","train_dl = DataLoader(train_dataset, batch_size=16, num_workers=1, pin_memory=True, shuffle=True)\n","val_dl = DataLoader(val_dataset, batch_size=16, num_workers=1, pin_memory=True)\n","\n","data = next(iter(train_dl))\n","input_data, input_labels = data\n","print(input_data.size())"]},{"cell_type":"markdown","metadata":{"id":"NCBjMhmzF-8v"},"source":["# Autoencoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1n6t0TfGA9N"},"outputs":[],"source":["class EEGEncoder(nn.Module):\n","  def __init__(self, encoding_dim, chunk_len, n_channels):\n","    super().__init__()\n","\n","    self.encoder_conv = nn.Sequential(\n","        nn.Conv2d(1, 4, 3, padding=1),\n","        nn.ReLU(),\n","        nn.BatchNorm2d(4),\n","        nn.Conv2d(4, 8, 3, padding=1),\n","        nn.ReLU(),\n","        nn.BatchNorm2d(8),\n","        nn.Conv2d(8, 16, 3, padding=0),\n","        nn.ReLU(),\n","    )\n","\n","    self.flatten = nn.Flatten()\n","\n","    self.encoder_lin = nn.Sequential(\n","        nn.Linear(2560, 128),\n","        nn.ReLU(),\n","        nn.Linear(128, encoding_dim)\n","    )\n","\n","  def forward(self, x):\n","    x = self.encoder_conv(x)\n","    x = self.flatten(x)\n","    x = self.encoder_lin(x)\n","    return x\n","\n","class EEGDecoder(nn.Module):\n","  def __init__(self, encoding_dim):\n","    super().__init__()\n","    self.decoder_lin = nn.Sequential(\n","        nn.Linear(encoding_dim, 128),\n","        nn.ReLU(),\n","        nn.Linear(128, 2560),\n","        nn.ReLU()\n","    )\n","\n","    self.unflatten = nn.Unflatten(dim=1, unflattened_size=(16, 8, 20))\n","\n","    self.decoder_conv = nn.Sequential(\n","        nn.ConvTranspose2d(16, 8, 3, padding=0),\n","        nn.BatchNorm2d(8),\n","        nn.ReLU(),\n","        nn.ConvTranspose2d(8, 4, 3, padding=1),\n","        nn.BatchNorm2d(4),\n","        nn.ReLU(),\n","        nn.ConvTranspose2d(4, 1, 3, padding=1),\n","    )\n","  \n","  def forward(self, x):\n","    x = self.decoder_lin(x)\n","    x = self.unflatten(x)\n","    x = self.decoder_conv(x)\n","    return x\n","\n","class EEGAutoencoder(nn.Module):\n","  def __init__(self, encoding_dim, chunk_len, n_channels):\n","    super().__init__()\n","    self.encoder = EEGEncoder(encoding_dim, chunk_len, n_channels)\n","    self.decoder = EEGDecoder(encoding_dim)\n","\n","  def forward(self, x):\n","    B, S, C = x.shape\n","    x = x.view(B, 1, S, C)\n","    x = self.encoder(x)\n","    x = self.decoder(x)\n","    x = x.view(B, S, C)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"6n4RWVJ85jb6"},"source":["# Transformer/Attention"]},{"cell_type":"markdown","metadata":{"id":"dO4AXp3ufg2y"},"source":["**Note**: Input data taking shape of (batch_size, length, num_channels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbv7jYil5lvX"},"outputs":[],"source":["class MultiheadAttention(nn.Module):\n","  def __init__(self, n_heads, hidden_size, dropout=0.1):\n","    super().__init__()\n","    self.n_heads = n_heads\n","    self.hidden_size = hidden_size\n","    self.dropout = dropout\n","\n","    assert hidden_size % n_heads == 0, \"Hidden size must be divisable by n_heads\"\n","    self.attention_head_size = int(hidden_size / self.n_heads)\n","    self.all_head_size = self.n_heads * self.attention_head_size\n","\n","    self.query = nn.Linear(hidden_size, self.all_head_size)\n","    self.key = nn.Linear(hidden_size, self.all_head_size)\n","    self.value = nn.Linear(hidden_size, self.all_head_size)\n","\n","    self.out = nn.Linear(hidden_size, hidden_size)\n","    self.attn_dropout = nn.Dropout(dropout)\n","    self.proj_dropout = nn.Dropout(dropout)\n","\n","    self.softmax = nn.Softmax(dim=-1)\n","\n","  def transpose_for_scores(self, x):\n","    new_x_shape = x.size()[:-1] + (self.n_heads, self.attention_head_size)\n","    x = x.view(*new_x_shape)\n","    return x.permute(0, 2, 1, 3)\n","\n","  def forward(self, x):\n","    # [Batch_size x Seq_length x Hidden_size]\n","    mixed_query_layer = self.query(x)\n","    mixed_key_layer = self.key(x)\n","    mixed_value_layer = self.value(x)\n","\n","    # [Batch_size x Num_of_heads x Seq_length x Head_size]\n","    query_layer = self.transpose_for_scores(mixed_query_layer)\n","    key_layer = self.transpose_for_scores(mixed_key_layer)\n","    value_layer = self.transpose_for_scores(mixed_value_layer)\n","\n","    scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n","    scores = scores / np.sqrt(self.attention_head_size)\n","    probs = self.attn_dropout(self.softmax(scores))\n","\n","    context_layer = torch.matmul(probs, value_layer)\n","    context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n","    new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size, )\n","    context_layer = context_layer.view(*new_context_layer_shape)\n","    out = self.proj_dropout(self.out(context_layer))\n","    return out\n","\n","class MLP(nn.Module):\n","  def __init__(self, hidden_size, mlp_dim, dropout=0.1):\n","    super().__init__()\n","    self.fc1 = nn.Linear(hidden_size, mlp_dim)\n","    self.fc2 = nn.Linear(mlp_dim, hidden_size)\n","    self.act_fn = nn.ReLU()\n","    self.dropout = nn.Dropout(dropout)\n","\n","    self._init_weights()\n","\n","  def _init_weights(self):\n","    nn.init.xavier_uniform_(self.fc1.weight)\n","    nn.init.xavier_uniform_(self.fc2.weight)\n","    nn.init.normal_(self.fc1.bias, std=1e-6)\n","    nn.init.normal_(self.fc2.bias, std=1e-6)\n","\n","  def forward(self, x):\n","    x = self.fc1(x)\n","    x = self.act_fn(x)\n","    x = self.dropout(x)\n","    x = self.fc2(x)\n","    x = self.dropout(x)\n","    return x\n","\n","class EncoderBlock(nn.Module):\n","  def __init__(self, n_heads, hidden_size, dropout=0.1):\n","    super().__init__()\n","    self.hidden_size = hidden_size\n","    self.attn_norm = nn.LayerNorm(hidden_size)\n","    self.ffn_norm = nn.LayerNorm(hidden_size)\n","    self.ffn = MLP(hidden_size, hidden_size, dropout)\n","    self.attn = MultiheadAttention(n_heads, hidden_size, dropout)\n","\n","  def forward(self, x):\n","    # Residual Self-Attention\n","    h = x\n","    x = self.attn(x)\n","    x = self.attn_norm(x)\n","    x += h\n","\n","    # Residual Feed-forward\n","    h = x\n","    x = self.ffn(x)\n","    x = self.ffn_norm(x)\n","    x += h\n","    return x\n","\n","class ClassifierBlock(nn.Module):\n","  def __init__(self, hidden_size, mlp_dim, dropout=0.1):\n","    super().__init__()\n","    self.fc1 = nn.Linear(hidden_size, mlp_dim)\n","    self.act_fn = nn.ReLU()\n","    self.fc2 = nn.Linear(mlp_dim, 4)\n","    self.softmax = nn.Softmax(dim=-1) \n","    self.dropout = nn.Dropout(dropout)\n","    self.ln1 = nn.LayerNorm(hidden_size)\n","    self.ln2 = nn.LayerNorm(mlp_dim)\n","\n","  def forward(self, x):\n","    x = self.ln1(x)\n","    x = self.fc1(x)\n","    x = self.act_fn(x)\n","    x = self.dropout(x)\n","    x = self.ln2(x)\n","    x = self.fc2(x)\n","    x = self.softmax(x)\n","\n","    return x\n","\n","class PositionalEncoding(nn.Module):\n","  def __init__(self, d_model, dropout=0.1, max_len=1000):\n","    super().__init__()\n","    self.dropout = nn.Dropout(dropout)\n","\n","    position = torch.arange(max_len).unsqueeze(1)\n","    div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","    pe = torch.zeros(max_len, 1, d_model)\n","    pe[:, 0, 0::2] = torch.sin(position * div_term)\n","    pe[:, 0, 1::2] = torch.cos(position * div_term)\n","    self.register_buffer('pe', pe)\n","\n","  def forward(self, x):\n","    x = x + self.pe[:x.size(0)]\n","    return self.dropout(x)\n","\n","\n","class TransformerClassifier(nn.Module):\n","  def __init__(self, input_size, n_heads, hidden_size, encoder, n_blocks=2, dropout=0.1, max_len=1000, patch_size=10):\n","    super().__init__()\n","    \n","    assert max_len % patch_size == 0, \"sequence length must be divisible by patch size\"\n","\n","    self.patch_size = patch_size\n","    self.max_len = max_len\n","    self.hidden_size = hidden_size\n","    self.pos_encoder = PositionalEncoding(hidden_size, dropout=dropout, max_len=max_len // patch_size)\n","    self.encoder = encoder\n","    self.encoder.eval()\n","    self.encoder_blocks = nn.ModuleList([EncoderBlock(n_heads, hidden_size, dropout) for _ in range(n_blocks)])\n","    self.classifier = ClassifierBlock(hidden_size, hidden_size, dropout)\n","\n","  def forward(self, x):\n","    B, S, C = x.shape\n","\n","    # some dimensionality tweaking to do embeddings\n","    # input is (B, S, C)\n","    x = x.view(B * S // self.patch_size, 1, self.patch_size, C)\n","    x = self.encoder.encoder(x)\n","    x = x.view(B, S // self.patch_size, self.hidden_size)\n","\n","    x = self.pos_encoder(x)\n","\n","    for encoder_block in self.encoder_blocks:\n","      x = encoder_block(x)\n","\n","    x = torch.mean(x, dim=1)\n","    probs = self.classifier(x)\n","    return probs\n"]},{"cell_type":"markdown","metadata":{"id":"9bBy7rZ25VQk"},"source":["# Training"]},{"cell_type":"markdown","source":["## Autoencoder"],"metadata":{"id":"9AZ-QvUGJwZN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3QnVFjQFP8-U"},"outputs":[],"source":["class AutoencoderTrainer:\n","    def __init__(self, epochs, batch_size, learning_rate, num_workers, train_data, valid_data, train_labels, valid_labels, patience, validate_after):\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self.learning_rate = learning_rate\n","        self.num_workers = num_workers\n","        self.train_data = train_data\n","        self.valid_data = valid_data\n","        self.train_labels = train_labels\n","        self.valid_labels = valid_labels\n","        self.patience = patience\n","        self.validate_after = validate_after\n","        self.chunk_len = 10\n","\n","    def train(self):\n","        the_last_loss = 100\n","        trigger_times = 0\n","        global_val_loss_minima = 100\n","            \n","        train_dataset = LoadData(data=self.train_data, labels=self.train_labels)\n","        train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, num_workers=self.num_workers,pin_memory=True)\n","        \n","        # Change class\n","        model = EEGAutoencoder(128, self.chunk_len, 22).to(device)\n","        \n","        criterion = nn.MSELoss()\n","        optimizer = torch.optim.Adam(model.parameters(),lr=self.learning_rate, weight_decay=1e-6)\n","        \n","    \n","        for epoch in range(self.epochs):\n","            print(\"Starting Training Epoch \" + str(epoch + 1))\n","            avg_loss = 0.0\n","            model.train()\n","            for i, data in enumerate(tqdm(train_dataloader)):\n","                inputs_all, targets_all = data\n","                inputs_all = inputs_all.to(device)\n","\n","                for i in range(len(inputs_all) // self.chunk_len):\n","                    inputs = inputs_all[:, i*self.chunk_len:(i+1)*self.chunk_len, ...]\n","\n","                    optimizer.zero_grad()\n","            \n","                    outputs = model(inputs)\n","            \n","                    loss = criterion(outputs, inputs)\n","            \n","                    writer.add_scalar(\"Loss/train\", loss, epoch)\n","            \n","                    loss.backward()\n","                    optimizer.step()\n","          \n","                avg_loss += loss.item()\n","\n","            # print(outputs[:5])\n","            # print(targets[:5])\n","\n","            print(f'Epoch {epoch + 1} \\t\\t Training Loss: {\\\n","                avg_loss / len(train_dataloader)}')\n","            \n","            if (epoch + 1) % self.validate_after == 0:\n","                val_loss, val_len = self.validate(model, criterion, epoch)\n","                print(f'Epoch {epoch + 1} \\t\\t Validation Loss: {\\\n","                    val_loss / val_len}')\n","                global_val_loss_minima = min(global_val_loss_minima, val_loss)\n","                # if val_loss > global_val_loss_minima:\n","                #     trigger_times += 1\n","                #     print('trigger times:', trigger_times)\n","        # \n","                #     if trigger_times >= self.patience:\n","                #         print('Early stopping!\\nStart to test process.')\n","                #         return best_model\n","        # \n","                # else:\n","                #     print('trigger times: 0')\n","                #     trigger_times = 0\n","                #     best_model = model\n","    \n","                the_last_loss = val_loss\n","              \n","            # torch.save(model.state_dict(), './Results/Models/saved_model_' + str(epoch + 1) + '.pth')\n","\n","        return model\n","\n","\n","    def validate(self, model, criterion, epoch):\n","        model.eval()\n","        with torch.no_grad():\n","            valid_loss = 0.0\n","            valid_dataset = LoadData(data=self.valid_data, labels=self.valid_labels)\n","            valid_dataloader = DataLoader(valid_dataset, batch_size=self.batch_size, num_workers=self.num_workers,pin_memory=True)\n","            for i, data in enumerate(valid_dataloader):\n","                inputs_all, _ = data\n","                inputs_all = inputs_all.to(device)\n","                \n","                for i in range(len(inputs_all) // self.chunk_len):\n","                    inputs = inputs_all[:, i*self.chunk_len:(i+1)*self.chunk_len, ...]\n","\n","                    outputs = model(inputs)\n","    \n","                    loss = criterion(outputs, inputs)\n","                    writer.add_scalar(\"Loss/validation\", loss, epoch)\n","    \n","                    valid_loss += loss.item()\n","        return valid_loss, len(valid_dataloader) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v_LH69fLX93h"},"outputs":[],"source":["autoencodertrainer = AutoencoderTrainer(epochs = 100, batch_size = 32, learning_rate = 0.0001, num_workers = 2, train_data=x_train, valid_data=x_valid, train_labels=y_train, valid_labels=y_valid, patience=5, validate_after=1)"]},{"cell_type":"code","source":["best_encoder = autoencodertrainer.train()"],"metadata":{"id":"9dJi9ptt3y5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(best_encoder, \"./encoder_weights\")"],"metadata":{"id":"YthFNjumADaT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_encoder = torch.load(\"./encoder_weights\")"],"metadata":{"id":"bg2HY91jbzLl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Transformer"],"metadata":{"id":"HRbeDB_MJ10J"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0DVnSVOL_PXW"},"outputs":[],"source":["class Trainer:\n","    def __init__(self, epochs, batch_size, learning_rate, num_workers, train_data, valid_data, train_labels, valid_labels, patience, validate_after):\n","      self.epochs = epochs\n","      self.batch_size = batch_size\n","      self.learning_rate = learning_rate\n","      self.num_workers = num_workers\n","      self.train_data = train_data\n","      self.valid_data = valid_data\n","      self.train_labels = train_labels\n","      self.valid_labels = valid_labels\n","      self.patience = patience\n","      self.validate_after = validate_after\n","\n","    def train(self):\n","        the_last_loss = 100\n","        trigger_times = 0\n","        global_val_loss_minima = 100\n","            \n","        train_dataset = LoadData(data=self.train_data, labels=self.train_labels)\n","        train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, num_workers=self.num_workers,pin_memory=True)\n","        \n","        # Change class\n","        model = TransformerClassifier(22, 4, 128, best_encoder, n_blocks=4, dropout=0.5).to(device)\n","        \n","        criterion = nn.CrossEntropyLoss().to(device)\n","        optimizer = torch.optim.Adam(model.parameters(),lr=self.learning_rate, weight_decay=1e-6)\n","        \n","    \n","        for epoch in range(self.epochs):\n","            print(\"Starting Training Epoch \" + str(epoch + 1))\n","            avg_loss = 0.0\n","            model.train()\n","            for i, data in enumerate(tqdm(train_dataloader)):\n","                inputs, targets = data\n","                inputs = inputs.to(device)\n","                targets = targets.to(device, dtype=torch.float64)\n","                optimizer.zero_grad()\n","        \n","                outputs = model(inputs)\n","        \n","                loss = criterion(outputs, targets)\n","        \n","                writer.add_scalar(\"Loss/train\", loss, epoch)\n","        \n","                loss.backward()\n","                optimizer.step()\n","        \n","                avg_loss += loss.item()\n","\n","            # print(outputs[:5])\n","            # print(targets[:5])\n","\n","            print(f'Epoch {epoch + 1} \\t\\t Training Loss: {\\\n","                avg_loss / len(train_dataloader)}')\n","            \n","            if (epoch + 1) % self.validate_after == 0:\n","                val_loss, val_len = self.validate(model, criterion, epoch)\n","                print(f'Epoch {epoch + 1} \\t\\t Validation Loss: {\\\n","                    val_loss / val_len}')\n","                global_val_loss_minima = min(global_val_loss_minima, val_loss)\n","\n","        if val_loss > global_val_loss_minima:\n","            trigger_times += 1\n","            print('trigger times:', trigger_times)\n","        \n","            if trigger_times >= self.patience:\n","                print('Early stopping!\\nStart to test process.')\n","                return best_model\n","        \n","        else:\n","            print('trigger times: 0')\n","            trigger_times = 0\n","            best_model = model\n","    \n","        the_last_loss = val_loss\n","              \n","            # torch.save(model.state_dict(), './Results/Models/saved_model_' + str(epoch + 1) + '.pth')\n","\n","        return model\n","\n","\n","    def validate(self, model, criterion, epoch):\n","        model.eval()\n","        with torch.no_grad():\n","            valid_loss = 0.0\n","            valid_dataset = LoadData(data=self.valid_data, labels=self.valid_labels)\n","            valid_dataloader = DataLoader(valid_dataset, batch_size=self.batch_size, num_workers=self.num_workers,pin_memory=True)\n","            for i, data in enumerate(valid_dataloader):\n","                inputs, targets = data\n","                inputs = inputs.to(device)\n","                targets = targets.to(device, torch.float64)\n","\n","                outputs = model(inputs)\n","\n","                loss = criterion(outputs, targets)\n","                writer.add_scalar(\"Loss/validation\", loss, epoch)\n","\n","                valid_loss += loss.item()\n","        return valid_loss, len(valid_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"er0bdwO-DdEa"},"outputs":[],"source":["trainer = Trainer(epochs = 25, batch_size = 64, learning_rate = 0.0001, num_workers = 2, train_data=x_train, valid_data=x_valid, train_labels=y_train, valid_labels=y_valid, patience=5, validate_after=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5vPfdJakDhjz"},"outputs":[],"source":["# torch.cuda.empty_cache()\n","best_model = trainer.train()\n","writer.flush()"]},{"cell_type":"code","source":["from torchsummary import summary\n","best_model = summary(best_model, (1000, 22), 64)"],"metadata":{"id":"Bx1iYDtRGk5r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_t5cVTx023jN"},"source":["# TESTING"]},{"cell_type":"markdown","metadata":{"id":"aKnHTQXzHjaI"},"source":["USING BEST MODEL FROM EARLY STOPPING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mum-q5asHm6b"},"outputs":[],"source":["model_test = best_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NEsbxSKVfeWZ"},"outputs":[],"source":["print(best_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NvClPmt7HrI4"},"outputs":[],"source":["test_dataset = LoadData(data=x_test, labels=y_test)\n","test_dataloader = DataLoader(test_dataset, batch_size=64, num_workers=2,pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hcy7np8g60PK"},"outputs":[],"source":["correct = 0\n","total = 0\n","for i, (inputs, targets) in enumerate(test_dataloader):\n","    # evaluate the model on the test set\n","    model_test.to(device)\n","    inputs = inputs.to(device)\n","    targets = targets.to(device)\n","    outputs = model_test(inputs)\n","    y = torch.argmax(targets, dim=1)\n","    pred_y = torch.argmax(outputs, dim=1)\n","    if i == 0:\n","        print(y[:10])\n","        print(pred_y[:10])\n","    total += targets.size(0)\n","    correct += (y == pred_y).sum().item()\n","\n","print(f'Accuracy of the network on the test images: {100 * correct // total} %')"]},{"cell_type":"markdown","metadata":{"id":"DEi-W528N74c"},"source":["# TENSORBOARD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lnl6h4Wx9Fhv"},"outputs":[],"source":["!tensorboard --logdir=Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FEgGhkuVKEEI"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["DEi-W528N74c"],"name":"247_Transformer","provenance":[{"file_id":"1HT9f6tdwQbo5vYcN7t_JB8e4YjwoBXRi","timestamp":1646249678067}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}